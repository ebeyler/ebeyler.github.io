---
---

@inproceedings{beylerVariationalInferenceBoolean2025,
  title = {Variational {{Inference}} on the {{Boolean Hypercube}} with the {{Quantum Entropy}}},
  booktitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}} ({{AISTATS}})},
  author = {Beyler, Eliot and Bach, Francis},
  year = {2025},
  abstract = {In this paper, we derive variational inference upper-bounds on the log-partition function of a pairwize Markov random fields on the Boolean hypercube, based on quantum relaxations of the Kullback-Leibler divergence. We then propose an efficient algorithm to compute these bounds based on primal-dual optimization. An improvement of these bounds through the use of "hierarchies", similar to sum-of-squares (SoS) hierarchies is proposed, and we present a greedy algorithm to select among these relaxations. We carry extensive numerical experiments and compare with state-of-the-art methods for this inference problem.},
  arxiv = {2411.03759},
  bibtex_show = {true},
  code = {https://github.com/ebeyler/variational_inference_quatum_entropy},
  abbr = {conference}
}

@article{beylerOptimalDenoisingScoreBased2025a,
  title = {Optimal {{Denoising}} in {{Score-Based Generative Models}}: {{The Role}} of {{Data Regularity}}},
  author = {Beyler, Eliot and Bach, Francis},
  year = {2025},
  abstract = {Score-based generative models achieve state-of-the-art sampling performance by denoising a distribution perturbed by Gaussian noise. In this paper, we focus on a single deterministic denoising step, and compare the optimal denoiser for the quadratic loss, we name ''full-denoising'', to the alternative ''half-denoising'' introduced by Hyv\{{\textbackslash}"a\}rinen (2024). We show that looking at the performances in term of distance between distribution tells a more nuanced story, with different assumptions on the data leading to very different conclusions. We prove that half-denoising is better than full-denoising for regular enough densities, while full-denoising is better for singular densities such as mixtures of Dirac measures or densities supported on a low-dimensional subspace. In the latter case, we prove that full-denoising can alleviate the curse of dimensionality under a linear manifold hypothesis.},
  arxiv = {2503.12966},
  bibtex_show=  {true},
  abbr = {preprint}
}